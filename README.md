
# OS(x86) learning

视频教程：
 - [操作系统](http://www.xuetangx.com/courses/course-v1:TsinghuaX+30240243X+sp/about)

参考资料：
 - [X86端口](http://bochs.sourceforge.net/techspec/PORTS.LST)
 - [分段机制与GDT,LDT](https://www.cnblogs.com/chenwb89/p/operating_system_003.html)

---
# OS启动

```text
X86 Memory Map（32位，最多4GB内存）

  |-----------| 0xFFFFFFFF (4GB)
  |           |
  |Free Space |
  |-----------|
  |           |
  |OS         |
  |-----------| 0x00100000 (1MB)
  |           |
  |BIOS       |
  |-----------| 0x000A0000 (640KB)
  |           |
  |Free Space |
  |-----------|
  |bootloader |
  |-----------| 0x00007C00
  |           |
  |Free Space |
  |-----------| 0x00000000

```

 - BIOS加载DISK的第一个扇区的bootloader至0x7C00，bootloader在DISK上找到OS并加载OS至MEM。
 - bootloader必须以0x55和0xAA结尾。

附：

现在新的电脑一般都采样UEFI的启动模式，电脑会在FAT分区上寻找指定的efi引导程序（如bootx64.efi），然后通过efi程序来加载内核和初始化系统。

---
# OS与外设、程序的交互

 - 系统调用：来于应用程序

POSIX API用于POSIX-based系统，包括UNIX、Linux等；而Win32 API用于Windows系统。

 - 异常：来于不良应用程序
 - 中断：来于外设

---
# OS内存管理

## 内存结构

内存大致包括3部分：

```
 ┌-------------------------┐
 |CPU寄存器，L1缓存，L2缓存| : CPU内部内存，速度快，但容量小
 |-------------------------|
 |主存                     |
 |-------------------------|
 |硬盘（虚拟内存）         |
 └-------------------------┘
```

## 内存地址空间管理

内存管理的基本要求：

 - 抽象：提供进程可访问的逻辑地址空间（可以对应到内存物理地址空间）
 - 保护：为进程提供独立的地址空间，保证程序间互不干扰
 - 共享：访问相同内存，提供进程间的交互
 - 虚拟化：利用硬盘提供更多的地址空间

内存管理的实现高度依赖于硬件，比如MMU（内存管理单元）用于负责处理CPU的内存访问请求。

## 连续内存分配

内存分配时会有内存碎片问题，包括外部碎片（进程序的内存无法得到利用）和内部碎片（分配给进程的内存无法得到利用）。

基本内存分配方法：

 - 第一匹配分配：遍历空间内存块，使用第一个满足需求的空闲内存块（易产生外碎片）
 - 最优匹配分配：遍历空间内存块，使用与需要求空间相差最小的空闲内存块（易产生微小外碎片）
 - 最差匹配分配：遍历空间内存块，使用与需要求空间相差最大的空闲内存块（易产生大的外碎片）

## 非连续内存分配

### 分段机制

软件：一个应用程序编译成代码段、数据段、栈段、堆段等部分
硬件：分段寻址

### 分页机制

 - 分页地址空间

物理内存划分成固定大小的帧，逻辑地址划分至相同大小的页；
使用 `页表，MMU/TLB` 转换逻辑地址到物理地址。

物理地址分页计算：

```text
地址总线：F+S 位
|----------------------------|
|帧位=F位  |  帧内偏移位=S位 |
|----------------------------|

物理地址addr(f, o) = 2^S * f + o
其中f : 帧号，共2^F帧，每帧2^S字节
    o : 帧内偏移地址，最大为2^S
```

逻辑地址（程序中）分页计算：

```text
逻辑地址宽度：P+S 位
|----------------------------|
|页位=P位  |  页内偏移位=S位 |
|----------------------------|

逻辑地址addr(p, o) = 2^S * p + o
其中p : 页号，总2^P页，第页2^S字节
    o : 页内偏移地址，最大为2^S
```

 - 分页寻址

用`页表`保存`逻辑地址`到`物理地址`之间的映射关系。映射通过数组来实现，具体来说，下标为页号p存储的是对应的帧号f，而物理地址偏移与逻辑地址偏移相等。

> 页映射到帧；
> 页是连续的虚拟内存；
> 帧是非连续的物理地址；
> 不是所有的页都有对应的帧。

### 页表

 - 页表访问速度问题

使用TLB(Translation Look-aside Buffer，具备快速访问性能)缓存近期访问页表项。

 - 页表存储空间问题

使用多级页表，减小不必要的页表项存储；但是页表级数变多时，映射访问就变得繁锁。如下是一个二级级表的示例：

```text
逻辑地址宽度：P1+P2+S 位
|----------------------------------------------|
|一级分页=P1位 |二级分页=P2位 | 页内偏移位=S位 |
|----------------------------------------------|

有两个页号，对应也有两个页表（数组）,通过index访问：
一级页表Table[2 ^ p1] = 二级页表的index
二级页表Table[index ] = 物理地址帧号f
```

建立反向页表，让页表与物理地址空间对应。可以这样理解，逻辑地址对应的物理地址存在，才将映射放入页表中，所以，这是一个大（逻辑）地址空间，到 小（物理）地址空间的映射，可以使用Hash表来建立这种映射关系，不过要注意Hash的碰撞问题。

```text
Hash(PID, p) = f
进行Hash计算时，可以加入程序PID等参数，缓解碰撞问题。
```

## 虚拟内存

理想的存储器：更大、更快、更便宜的非易失性存储器

### 覆盖技术

为了在较小的内存中运行较大的程序，将程序划分成若干功能相互独立的功能模块：

 - 必要部分：放于内存
 - 可选部分：平在放于外存，需要时才装入内存

不存在调用关系的模块不必同时装入内存，从而可以相互覆盖。
但是，为了确定覆盖关系，会增加编程的复杂度，而从外存装载数据到内存，会增加时间开销。

```
                                   -------------
       A(20K)             A    -> |常驻区(20K)  |
      /      \                    |-------------|
 B(50K)     C(30K)        B,C  -> |覆盖区0 (50K)|
   |        /   \                 |-------------|
 D(30K) E(20K)  F(40K)    D,E,F-> |覆盖区1 (40K)|
                                 -------------

另一种覆盖方法：
 A     -> 常驻区 (20K)
 B,E,F -> 覆盖区0 (50K)
 C,D   -> 覆盖区1 (30K)
```

### 交换技术

将暂时不运行的程序（进程地址空间）放入外存，从而获取内存空间。交换技术发生在程序之间，而覆盖技术发生在程序的模块之间。

```text
|-----------|               |-----------|
| Os Memory |               |           |
|-----------|               |           |
|           |               |-----------|
|           | --Swap out--> | Process1  |
|           |               |-----------|
|           |               |           |
|           |               |-----------|
|           | <--Swap in--- | Process2  |
|-----------|               |-----------|
  Memory                Disk
```

交换时需要考虑：
 - Swap时机：当内存空间不够时进行Swap；
 - Swap大小：Swap区应该足够大，能放入所有用户程序；
 - Process重定位：采用动态地址映射。

### 虚存技术

基于页式或段式内存管理的基础上实现：

 - 装载：只加载当前需要的部分页面或段到内存；
 - 执行：如果需要指令或数据尚未在内存，则由处理器通知操作系统加载相应的页面或段；同时，将不需要的页面和段放入外存中。

虚拟内存的特征：

 - 大的用户空间：物理内存和外存相结合，可以提供更大的虚拟内存空间；
 - 部分交换：与交换技术相比，是部分虚拟地址空间的调入和调出；
 - 不连续性：物理内存分配不连续，虚拟地址空间使用的不连续。

### 页面置换

发生缺页中断时，且内存页面已满时，选择某个物理内存页被置换。

几种局部页面置换算法：

 - 最优页面置换算法
发生缺页中断时，置换等待时间最长的页面。实际中无法实现，因为操作系统不知道未来哪个页面的等行时间最长。不过可以作为其它页面置换算法的性能评价依据。

 - 先进先出算法（FIFO）
置换在内存中驻留时间最长的页面。性能较差，很少单独使用。使用FIFO算法，有时物理页帧分配增加，缺页机率增大，称为Belay现象。

 - 最近最久未使用算法（Least Recently Used, LRU）
置换最久未使用的那个页面。LRU算法需要记录各个页面使用时间的先后顺序。

 - 时钟页面置换算法（Clock）
与LRU近似，是对FIFO的改进。根据页面访问标志位，置换相对较久未使用的页面（或者等待时间最久且未使用的页面）。

 - 二次机会法
有修改的页面保留的机率更大，而没有修改的页修被置换的机率更大。根据页面访问标志位和读写标志位，来确定置换的页面。

```text
Used, Write -> Used, Write
  0 , 0          (Replace)
  0 , 1          0 , 0 (Keep)
  1 , 0          0 , 0 (Keep)
  1 , 1          0 , 1 (Keep)

Used: 访问标志位，最近是否被访问
Write: 读写标志位，是否有修改
```

 - 最不常用算法（Least Frequently Used, LFU)
置换访问次数最少的页面。

---
# OS进程

## 进程概念

进程是一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程，而程序是一个静态的二进制代码。

 - 进程与程序的联系：

```text
 1 程序是产生进程的基础
 2 程序的每次运行构成不同的进程
 3 进程是程序功能的体现
 4 一个程序可以对应多个进程（多次执行）
 5 一个进程可以包括外个程序（调用关系）
```

 - 进程与程序的区别：

```text
 1 进程是动态的，程序是静态的
 2 进程是暂时的，程序是永久的
 3 进程与程序的组成不同：进程的组成包括程序、数据和进程控制块（进程状态信息）
```

 - 进程的特点：

```text
 1 动态性：可以动态创建、结束进程
 2 并发性：进程可以被独立调度并占用处理机运行
           【并发：一个短的时间段内，有多个进程运行，一个CPU也可以执行并发
             并行：一个时刻有多个进程运行，只有多个CPU（多核CPU）才能并行】
 3 独立性：不同进程的工作不相互影响
 4 制约性：因访问共享数据/资源或进程同步而产生制约
```

## 进程管理

### 进程序控制块

进程控制块（Process Control Block, PCB）：操作系统管理控制进程运行所用的信息集合，是进程存在的唯一标志。

 - PCB的三大类信息：

```text
 1 进程标识信息：如进程标识、父进程标识、用户标识
 2 处理机状态信息保存区：保存进程运行的现场信息
 3 进程控制信息：用于进程的管理与控制
```

 - PCB的组织方式：

```text
 1 链表：同一状态的进程其PCB组成一个链表，多个状态对应多个不同链表。
         链表能很好的实现进程的动态创建与删除。
 2 索引表：同一状态的进程归于一个index表（由index指向PCB），多个状态对应不同的index表。
           进程数相对固定时，用数组能较好的管理进程。
```

### 进程生命期

 - 进程生命期可能的状态：

```text
 1 进程创建
 2 进程运行
 3 进程等待（阻塞）：进程只能自身阻塞自身
 4 进程唤醒：进程只能被别的进程或操作系统唤醒
 5 进程结束
```

进程的三个基本状态：运行状态（Running）、就绪状态（Ready）、阻塞状态（Blocked）
进程的其它状态：创建状态（New）、结束状态（Exit）

```text
                          6
            ┌--> Running ---> Exit
            |      |  |
            |2    3|  |5
      2     |      |  |
 New ---> Ready <--┘  └--> Blocked
            ^                 |
            └-----------------┘
                 4
 1. 进入就绪队列
 2. 被调度
 3. 时间片执行完毕
 4. 束件发生
 5. 等待事件
 6. 结束
```

### 进程挂起

挂起（Suspend）是指把一个进程从内存转到外存。
解挂/激活（Activate）是指把一个进程从外存转到内存。
进程在挂起时，意味着没有占用内存空间。处于挂起状态的进程映像在磁盘上。

 - 阻塞挂起状态（Blocked-suspend）：进程在外存等待某事件的出现
 - 就绪挂起状态（Ready-suspend）：进程在外存，但只要进入内存，即可运行


## 线程

### 线程管理

线程（Thread）是进程中的一条执行流程。

 - 线程的优点：

```text
 1 一个进程可以同时存在多个线程
 2 各个线程之间可以并发执行
 3 各个线程之间可以共享地址空间和文件等资源
```

 - 线程的缺点： 一个线程崩溃，会导致所属进程的所有线程崩溃。

 - 线程与进程比较

```text
 1 进程是资源分配单位，线程是CPU调度单位
 2 进程拥有一个完整的资源平台，而线程只独享必不可少的资源（如寄存器和栈等）
 3 线程同样具有就绪、阻塞和执行三种基本状态，同样具有状态之间的转换关系
 4 线程能减少并发执行的时间和空间开销
```

### 线程实现

 - 用户线程（User Thread）：在用户空间实现的线程机制，不需要依赖于操作系统的内核，由一组用户级的线程库函数完成线程管理。

用户线程缺点：

```text
 1 如果一个线程发起系统调用而阻塞，则整个进程在等待
 2 当一个线程开始运行后，除非它主动交出CPU的使用权，则它所在进程的其它线程将无法运行
 3 因为时间片是分配给进程的，所在在多线程执行时，每个线程得到的时间片较少，执行相对较慢
```

 - 内核线程（Kernel Thread）：指在操作系统的内核中实现的一种线程机制，由操作系统的内核来完成线程的创建、终止和管理。

 - 轻量级进程（LightWeight Process）：是内核支持的用户线程。一个进程可有一个或多个轻量级进程，每个轻量级进程由一个单独的内核线程支持。


## 进程调度

### 基本介绍

 - 分类

 非抢占式： 调度程序必须等待事件结束
 抢占式（内核态抢占，用户态抢占）：进程可以被打断

 - 调度评价指标

 CPU使用率：CPU处于忙状态所占时间的百分比
 吞吐量：单位时间内完成的进程数量
 周转时间：一个进程从初始化到结束，包括所有等待时间所花费的时间
 等待时间：进程在就绪队列中的总时间
 响应时间：从一个请求被提交到产生第一次相应所花费的总时间

### 调度算法

 - FCFS: 先来先服务

实现简单，但没有考虑抢占调度。

 - SPN(SJF) SRT: 短进程优先（短作业优先）短剩余时间优先

按照预测的完成时间来将任务入队；可以是抢占式或非抢占式的。
SRT是抢占式的，SPN是非抢式的。

 - HRRN: 最高响应比优比

```
R = (W+S)/S
W: Waiting time 等待时间
S: Service time 服务时间
选择R值最高的进程（等待时间最长）
```

在SPN的基础上改进，综合考虑执行时间和等待时间；
关注进程等待了多长时间，防止无期限推迟；
非抢占式。

 - Round Robin: 轮循

设置一个时间片，进程挨个轮循执行一个时间片的时间。

 - Multilevel Feedback Queues: 多级反馈队列

进程可以在不同优先级的级列中移动；
优先级越高，时间片越大；
任务在当前的时间片中没有完成，则降到下一个优先级。

 - Fair Share Scheduling: 公平共平调度

公平是第一要素；
控制用户对系统资源的访问，在用户级别实现公平调度。

### 实时调度

 - 强实时系统：需要在保证的时间内完成重要任务，必须完成
 - 弱实时系统：要求重要的进程的优先级更高，尽量完成，并非必须

 - RM(Rate Monotonic) 速度单调调度
最佳静态优先级调度，通过周期安排优先级，周期越短优先级越高，执行周期最短的任务。

 - EDF(Earliest Deadline First) 最早期限调度
最佳的动态优先级调度，Deadline越早优先级越高，执行Dealine最早的任务。

# OS进程同步

## 互斥量

### Critial Section（临界区）

指进程中的一段需要访问共享资源，且当另一个进程处于相应的代码区域时，便不会被执行的代码区域。

 - 基于硬件中断

没有中断，没有上下文切换，因此没有并发。

进入临界区：禁用中断
离开临界区：开启中断

 - 基于软件的解决方案

针对两个进程同步的Peterson算法：

```cpp
int turn;       // 该哪个进程进入临界区
bool flag[];    // 指示进程是否准备好进入临界区

// Thread a                         // Thread b
do {                                do {
    flag[a] = true;                         flag[b] = true;
    turn = b;                               turn = a;
    while (flag[b] && turn == b);           while (flag[a] && turn == a);
    enter_critial_section();                enter_critial_section();

    flag[a] = false;                        flag[b] = false;
    exit_critial_section();                 exit_critial_section();
}   while(true);                      }     while(true);

```

 - 更高级的抽象

需要硬件提供原子指令。

Test-and-set（测试和置位）：

```cpp
// 从内存取值 -> 测试值是否为1（返回真或假）-> 内存值设置为1
bool TestAndSet(bool *tartget) {
    bool rv = *target;
    *target = true;
    return rv;
}
```

Exchange（交换）：

```cpp
// 交换两个内存值并返回
void Exchange(bool *a, bool *b) {
    bool tmp = *a;
    *a = *b;
    *b = tmp;
}
```

利用原子指令实现Lock（锁）：

```cpp
class Lock {
    int value = 0;
    WaitQueue q;
}

// 忙等待方式
Lock::Acquire() {
    while (TestAndSet(value));
}
Lock::Release() {
    value = 0;
}

// 无忙等待方式
Lock::Acquire() {
    while (TestAndSet(value)) {
        q.add(current_TCB);
        schedule();
    };
}
Lock::Release() {
    value = 0;
    q.remove(current_TCB);
    wakeup();
}
```

### Mutual Exclusion（互斥）
当一个进程处理临界区并访问共享资源时，没有其它进程会处于临界区且访问任何相同的共享资源。

### Dead Lock（死锁）

两个或以上的进程，在相互等待对方完成特定任务，而最终没法将自身任务进行下去。

### Starvation（饥饿）

一个可执行的进程，被调度器忽略，虽然处于可执行状态但却不被执行。

## 信号量

### 基本原理

一个整型(sem)，两个原子操作：

 - P(): sem-1，当sem<0，睡眠等待，否则继续
 - V(): sem+1，当sem<=0，唤醒一个等待的进程

```cpp
// 生产者消费者模型
class BoundedBuffer {
    mutex = new Semaphore(1);           // 互斥信号量，保证Buffe数据同步
    fullBuffer = new Semaphore(0);      // 开始Buffer可用数据为0
    emptyBuffer = new Semaphore(n);     // 开始Buffer可用空间为n
}
BoundedBuffer::Deposit(c) {
    emptyBuffer()->P();                 // Buffer可用空间减1
    mutex->P();                         // 获取锁，开始修改Buffer
    <Add c to the buffer>;
    mutex->V();                         // 释放锁
    fullBuffer->V();                    // Buffer可用数据加1
}
BoundedBuffer::Remove(c) {
    fullBuffer->P();                    // Buffer可用数据减1
    mutex->P();                         // 获取锁，开始修改Buffer
    <Remove c from the buffer>;
    mutex->V();                         // 释放锁
    emptyBuffer()->V();                 // Buffer可用空间加1
}
```

### 实现

```cpp
class Semaphore {
    int sem;
    WaitQueue queue;
}
Semaphore::P() {
    sem --;
    if (sem < 0) {
        <Add this thread t to queue>;
        Block(p);
    }
}
Semaphore::V() {
    sem ++;
    if (sem <= 0) {
        <Remove a threat t from queue>;
        Wakeup(t);
    }
}
```

## 管程（条件量）

管程定义：
 - 一个锁：指定临界区，保证访问共享数据的互斥性
 - 0或多个条件变量：等待/通知信号用于管理并发访问共享数据

### 实现

```cpp
class Condition {
    int numWaiting = 0;         // 当前等待线程的个数
    WaitQueue queue;
}
Condition::Wait(lock) {
    numWaiting ++;
    <Add this thread t to queue>;
    lock->Release();            // （释放实例中的锁）
    schedule();                 // 选择下一个线程执行
    lock->Require();
}
Condition::Signal() {
    if (numWaiting > 0) {
        <Remove a thread t from queue>;
        wakeUp(t);              // 唤醒等待的线程
        numWaiting --;
    }
}
```

 - 实例

```cpp
// 生产者消费者模型
class BoundedBuffer {
    Lock lock;
    int count = 0;              // 开始Buffer数据为空
    Condition notFull, notEmpty;
}
BoundedBuffer::Deposit(c) {
    lock->Acquire();            // 对管程共享数据加锁（所以Condition::Wait中需要先释放锁）
    while (count == n) {
        notFull.Wait(&lock);    // 等待Buffer空间
    }
    <Add c to the buffer>;
    count ++;
    notFull->Signal();          // 唤醒等待Buffer数据的线程
    lock->Release();
}
BoundedBuffer::Remove(c) {
    lock->Acquire();            // 对管程共享数据加锁
    while (count == 0) {
        notEmpty.Wait(&lock);   // 等待Buffer数据
    }
    <Remove c from the buffer>;
    count --;
    notFull->Signal();          // 唤醒等待Buffer空间的线程
    lock->Release();
}
```

## 经典实例

 - 读者-写者问题
 - 哲学家就餐问题


# OS进程通信（IPC）

通信分类：

 - 直接/间接通信
 - 阻塞/非阻塞通信（同步/异步）

## 通信方式

 - Signal（信号）：软件中断通知事件处理，不适合传输数据
 - 管道（pipe）：用于数据交换
 - 消息队列：按FIFO来管理消息
 - 共享内存：直接通信式，快速方便地共享数据，需要同步访问数据

# OS文件系统

## 基本概念

 - 文件系统：一种用于持久性存储的系统抽象
 - 文件：文件系统中一个单元的相关数据在操作系统中的抽象
 - 文件描述符
 - 目录：一类特殊的文件，用于组织文件
 - 挂载：一个文件系统需要先挂载才能被访问
 - 文件别名：硬链接、软链接
 - 文件系统种类：磁盘文件系统、数据库文件系统、日志文件系统、网络/分布式文件系统、虚拟文件系统

## 虚拟文件系统

 - 目的：对所有不同文件系统的抽象
 - 功能：
   - 提供相同的文件和文件系统接口
   - 管理所有文件和文件系统关联的数据结构
   - 高效查询例程，遍历文件系统
   - 与特定文件系统模块的交互

```
上层：虚拟(逻辑)文件系统
下层：特定文件系统模块

┌────────────────────────────────┐
│文件/文件系统API                │
├────────────────────────────────┤
│虚拟文件系统层                  │
├─────────────────┬──────────────┤
│ext,fat,iso9660  │nfs,smb       │
├─────────────────┼──────────────┤
│Device I/O       │Netwrok I/O   │
└─────────────────┴──────────────┘

```

 - 文件系统数据结构：
   - 卷控制块（每个文件系统一个）
   - 文件控制块（每个文件一个）
   - 目录节点（每个目录一个）

## 文件分配

文件分配是指如何为一个文件分配数据块。

 - 分配方式：连续分配，链式分配，索引分配
 - 指标：高效（存储利用等），表现（访问速度等）

### 连续分配

 - 文件头指定起始块和长度
 - 位置/分配策略：最先匹配，最佳匹配
 - 优势：文件读取表现好，高效的顺度和随机访问
 - 劣势：碎片，文件增长问题

### 链式分配

 - 文件以数据块链表方式存储
 - 文件头包含第一块和最后一块的指针
 - 优点：创建、增减容易，没有碎片
 - 缺点：不可能进行真正的随机访问，可靠性

### 索引分配

 - 为每个文件创建一个名为索引数据块，包含了每个数据块的指针
 - 文件头包含索引数据块
 - 优点：创建、增减很容易，没有碎片，支持直接访问
 - 缺点：文件很小时，存储索引的开销大，处理大文件问题

